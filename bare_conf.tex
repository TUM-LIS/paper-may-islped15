\documentclass[conference]{IEEEtran}
\usepackage{graphicx}
\usepackage{soul}
\begin{document}

\title{Realization of Fine-grained Sequential Approximate Circuits using Fault Emulation}


\author{\IEEEauthorblockN{BLIND REVIEW}
\IEEEauthorblockA{}
\and
\IEEEauthorblockN{BLIND REVIEW}
\IEEEauthorblockA{}
}


% make the title area
\maketitle


\begin{abstract}
%\boldmath
Approximate Computing has recently drawn interest due to its promise to substantially decrease the power consumption of integrated circuits. By tolerating a certain incorrectness at a circuit output, it can be operated at a more resource-saving state. For instance, parts of the circuit could be switched off or driven at sub-threshold voltage. Clearly, not all applications are suitable for this approach. Especially applications from the signal and image processing domain are suitable, due to their intrinsic tolerance to imprecision. But even in these circuits, one has to be very careful when and where to approximate a circuit, in order not to violate a minimum QoS.\\
In this paper we are presenting a complete approach to generate approximate circuits from existing deterministic implementations. The flow reaches from application-driven QoS definition down to approximated RTL. We are using FPGA-based fault emulation of the circuit in order to find out how faults, i.e. imprecisions in the circuit, affect the circuit behavior.\\
Most existing approaches only consider combinational circuits. Compared to existing approaches considering sequential circuits, our approach is very fast and accurate due to the FPGA-based emulation. And furthermore, we are able to tune the resulting precision to the defined QoS, in order to bring out the best gain of the approximation.
\end{abstract}

\IEEEpeerreviewmaketitle



\section{Introduction}
Due to increasing demand for low-power applications during the last decade, energy-efficiency has become a major factor in embedded systems design. However, voltage-scaling, the most efficient technique to save power, can not be further applied in conventional systems. The sophisticated scaling of MOSFET feature-sizes, makes circuits prone to even small voltage variations, when operating in the near-threshold area, and hence susceptible to errors within the circuit. And furthermore, as a consequence thereof, the decreased operating frequency is not acceptable in many cases.
\subsubsection*{Approximate Computing}
One emerging approach to tackle this problem is captioned by the term \emph{Approximate Computing}. Approximate computing tries to increase the energy-efficiency by tolerating a certain uncertainty at the circuit outputs, i.e. the result of a operation. The term covers a variety of points of application, from programming level to transistor level, as well as techniques on how to reduce the power consumption. Power can be saved for instance by calculating with a reduced precision, i.e. removing parts of the circuit, a method clearly related to fixed-point arithmetic. However, approximate computing introduces dynamics to this field. It proposes to switch off and on the precision depending on the actual demand of the application. Another way can be to over-scale the voltage, and hence accept timing violations or nose-based faults. Another method, we want to explicitly mention here, is related to circuit soft-error reliability. Approximate computing can be used to reduce the hardware overhead due to fault tolerance mechanisms, e.g. by omitting redundancy wherever it is not absolutely needed. Clearly this approach is not applicable for all kind of applications. Especially applications form the signal processing domain are suitable. These applications usually have an inherent imprecision tolerance. They have to deal with the human (imperfect) perception, have redundant input data in order to deal with noisy data. For a comprehensive coverage of the topic, we refer to the work of Han et al. \cite{han_approximate_2013}.
\subsubsection*{Motivational Example}
Consider any arbitrary wireless communication system, e.g. like IEEE 802.11 Wi-Fi. Like any similar system, 802.11 is as system, designed to deal with noise on the received radio signal. It is designed to transmit data error-free in a good, as well as in a bad radio channel. If the channel is noisy between two stations, the system switches to a lower-order modulations scheme, resulting in a lower data-rate, in order to be more robust. However, internally the hardware is working with the same precision independent on the signal quality, which might not be necessary. For instance, such systems usually consist of one or more channel-coding schemes. At the receiving end, the decoder extracts the payload from the received signal, not matter if it was noisy or not. Hence, if the SNR of the signal is high, the decoder could work less precise, requiring less power, and still extract the payload error-free. Depending on the signal quality such a dynamic approximate system could then switch between different power/precision states without having any influence on the performance.
\subsubsection*{Problem Description}
Even if applications mentioned above seem to be applicable for approximate computing, parts of the circuit cannot be easily switched off, or faults cannot be tolerated everywhere in the circuit. It is crucial to know which parts of the circuit influence the functionality in which way.
\subsubsection*{Related Work}
\subsubsection*{Contribution of this Work}






\section{Methodology}
\subsection{faultify - Probability-aware Fault Emulation}
\hl{grafik; probability-awareness}


\subsection{Application-reasoned Approximation }
Clearly it is necessary to reason the required precision of a circuit, i.e. the maximum tolerable error probability of the output pins, from the application that utilizes that particular circuit. 
\begin{figure}[htb]
  \centering
  \includegraphics[width=.5\textwidth]{figs/metrics_qr}
  \caption{Tolerable imprecision of a QR decomposition, part of a 8x8 MIMO zero-forcing equalizer, for different signal qualities and a target BER=$0.01$}
  \label{fig:metrics_qr}
\end{figure}
\begin{figure}[htb]
  \centering
  \includegraphics[width=.5\textwidth]{figs/metrics_sobel}
  \caption{Tolerable imprecision of a \emph{sobel} filter for different target qualities (PSNR)}
  \label{fig:metrics_sobel}
\end{figure}


\subsection{Approximation of Sequential Circuits}
% Hier keine Figures, verweis auf exp. results
\hl{algorithm, warum keine optimierung}
\subsubsection{Data-path Separation}
\subsubsection{High Variance Registers}
\subsubsection{Coarse-grained Approximation}
\subsubsection{Fine-grained Approximation}


















\section{Experimental Results}
\hl{Explain Circuit}\\
\begin{tabular} {| l | l | c | c |}
\hline
Name & Description & Gates & Flip-flops \\
\hline\hline
FIR & 16-tap FIR filter & xx & xx \\
IIR & 8-tap IIR filter & xx &xx \\
DCT4 & 4-input DCT & xx & xx \\
DCT8 & 8-Input DCT & xx & xx \\
fpu100 & 32-bit floating point unit & xx & xx \\
QR & QR decomposition & xx & xx \\
vitdec & Viterbi decoder (131,81) & xx & xx \\
\hline
\end{tabular}
\subsection{FPGA target}
\hl{power/area table}
\subsection{ASIC target}
\hl{power area table}














\section{Conclusion}






\section*{Acknowledgment}





% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section
\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,islped}





% that's all folks
\end{document}


