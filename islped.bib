
@inproceedings{daveau_industrial_2009,
	title = {An industrial fault injection platform for soft-error dependability analysis and hardening of complex system-on-a-chip},
	doi = {10.1109/IRPS.2009.5173253},
	abstract = {This paper presents a fault injection platform that is currently developed and used to perform soft-error dependability analysis and hardening of complex {SoCs.} Primarily, it is oriented toward safety analysis, safety requirement conformance testing and hardening of complex {SoCs.} This platform makes use of clusters of hardware emulation resources available for {SoC} verification to achieve massive faults injection capabilities. It is able to distribute fault injection campaigns across multiple heterogeneous emulation platforms to achieve high fault coverage. It is able to virtually handle almost any circuit size and is designed to support all kind of designs. We present the first results obtained on a small design, the Leon2 {IP}, on which exhaustive fault injection have been performed.},
	booktitle = {Reliability Physics Symposium, 2009 {IEEE} International},
	author = {Daveau, J.-M. and Blampey, A. and Gasiot, G. and Bulone, J. and Roche, P.},
	month = apr,
	year = {2009},
	keywords = {Circuit faults, circuit reliability, complex system-on-a-chip hardening, conformance testing, Emulation, Failure analysis, fault diagnosis, Flip-flops, hardening, hardware, industrial fault injection platform, Instruments, Intellectual property, Leon2 {IP}, logic testing, Performance analysis, safety, safety analysis, safety requirement conformance testing, {SoC} verification, soft-error dependability analysis, System-on-a-chip, system-on-chip},
	pages = {212--220},
	file = {IEEE Xplore Abstract Record:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/JDDZDPKF/articleDetails.html:text/html}
},

@inproceedings{may_fpga-based_2012,
	title = {An {FPGA-based} probability-aware fault simulator},
	doi = {10.1109/SAMOS.2012.6404190},
	abstract = {A recent approach to deal with the challenges that come along with the shrinking feature size of {CMOS} circuits is probabilistic computing. Those challenges, such as noise or process variations, result in a certain probabilistic behavior of the circuit and its gates. Probabilistic Computing, also referred to as {pCMOS}, does not try to avoid the occurrence of errors, but tries to determine the probability of errors at the output of the circuit, and to limit it to a value that the specific application can tolerate. Past research has shown that probabilistic computing has potential to drastically reduce the power consumption of circuits by scaling the supply voltage of gates to a value where they become non-deterministic, while tolerating a certain amount of probabilistic behavior at the output. Therefore, one main task in the design of {pCMOS} circuits is to determine the error probabilities at the output of the circuit, given a combination of error probabilities at the gates. In earlier work, {pCMOS} circuits have been characterized by memory-consuming and complex analytical calculations or by time-consuming software-based simulations. Hardware-accelerated emulators exist in large numbers, but miss the support of injecting errors with specified probabilities into as many circuit elements the user specifies at the same time. In this paper, we propose an {FPGA-based} fault simulator that allows for fast error probability classification, injection of errors at gate- and {RT-level}, and that is furthermore independent on the target architecture. Moreover, we demonstrate the usefulness of such a simulator by characterizing the probabilistic behavior of two benchmark circuits and reveal their energy-saving capability.},
	booktitle = {2012 International Conference on Embedded Computer Systems ({SAMOS)}},
	author = {May, D. and Stechele, W.},
	month = jul,
	year = {2012},
	keywords = {benchmark circuits, Circuit faults, energy saving capability, Error probability, error probability classification, fault simulation, field programmable gate arrays, {FPGA} based fault simulator, {FPGA} based probability aware fault simulator, hardware accelerated emulators, Instruments, Integrated circuit modeling, Logic gates, memory consuming, {pCMOS} circuits, power consumption, probabilistic behavior, probabilistic computing, Probabilistic logic, probability, process variations, shrinking feature size, time consuming software based simulation},
	pages = {302--309},
	file = {IEEE Xplore Abstract Record:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/AZZVSCGJ/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/APNV8XF9/Daveau et al. - 2009 - An industrial fault injection platform for soft-er.pdf:application/pdf;IEEE Xplore Full Text PDF:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/KAQZS7TU/May and Stechele - 2012 - An FPGA-based probability-aware fault simulator.pdf:application/pdf}
},

@article{constantinescu_trends_2003,
	title = {Trends and challenges in {VLSI} circuit reliability},
	volume = {23},
	issn = {0272-1732},
	doi = {10.1109/MM.2003.1225959},
	abstract = {Deep-submicron technology is having a significant impact on permanent, intermittent, and transient classes of faults. This article discusses the main trends and challenges in circuit reliability, and explains evolving techniques for dealing with them.},
	number = {4},
	journal = {{IEEE} Micro},
	author = {Constantinescu, C.},
	month = jul,
	year = {2003},
	keywords = {Circuit faults, circuit reliability, Copper, deep-submicron technology, Electromigration, fault tolerance, faults, Frequency, integrated circuit interconnections, integrated circuit reliability, intermittent faults, Microprocessors, permanent faults, Random access memory, Semiconductor device manufacture, transient faults, Very large scale integration, {VLSI}, Voltage},
	pages = {14--19},
	file = {IEEE Xplore Abstract Record:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/RCSDRJQU/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/DVS822RQ/Constantinescu - 2003 - Trends and challenges in VLSI circuit reliability.pdf:application/pdf}
},

@article{dreslinski_near-threshold_2010,
	title = {Near-Threshold Computing: Reclaiming Moore's Law Through Energy Efficient Integrated Circuits},
	volume = {98},
	issn = {0018-9219},
	shorttitle = {Near-Threshold Computing},
	doi = {10.1109/JPROC.2009.2034764},
	abstract = {Power has become the primary design constraint for chip designers today. While Moore's law continues to provide additional transistors, power budgets have begun to prohibit those devices from actually being used. To reduce energy consumption, voltage scaling techniques have proved a popular technique with subthreshold design representing the endpoint of voltage scaling. Although it is extremely energy efficient, subthreshold design has been relegated to niche markets due to its major performance penalties. This paper defines and explores near-threshold computing ({NTC)}, a design space where the supply voltage is approximately equal to the threshold voltage of the transistors. This region retains much of the energy savings of subthreshold operation with more favorable performance and variability characteristics. This makes it applicable to a broad range of power-constrained computing segments from sensors to high performance servers. This paper explores the barriers to the widespread adoption of {NTC} and describes current work aimed at overcoming these obstacles.},
	number = {2},
	journal = {Proceedings of the {IEEE}},
	author = {Dreslinski, {R.G.} and Wieckowski, M. and Blaauw, D. and Sylvester, D and Mudge, T.},
	month = feb,
	year = {2010},
	keywords = {Clocks, {CMOS} integrated circuits, {CMOS} technology, Computer architecture, Design optimization, energy conservation, Energy consumption, energy efficiency, energy efficient integrated circuits, Fabrication, High performance computing, integrated circuit design, Moore's Law, Moores law, near-threshold computing, parallel processing, power integrated circuits, power-constrained computing, Threshold voltage, {VLSI}},
	pages = {253--266},
	file = {IEEE Xplore Abstract Record:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/B22UXJJA/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/J7FAN3R9/Dreslinski et al. - 2010 - Near-Threshold Computing Reclaiming Moore's Law T.pdf:application/pdf}
},

@inproceedings{patel_evaluating_2003,
	title = {Evaluating Circuit Reliability under Probabilistic Gate-Level Fault Models},
	abstract = {Circuit reliability is an increasingly important design consideration for modern logic circuits. To this end, our work focuses on the evaluation of circuit reliability under probabilistic gate-level fault models that can capture both soft errors, e.g., radiation-related, and spatially-uniform manufacturing defects. This basic task can, in principle, be used (i) by synthesis procedures to select more reliable circuits, and (ii) to estimate yield for electronic nanotechnologies where high defect density is expected.},
	booktitle = {In International Workshop on Logic Synthesis ({IWLS)}},
	author = {Patel, Ketan N. and Markov, Igor L. and Hayes, John P.},
	year = {2003},
	pages = {59–64},
	file = {Citeseer - Full Text PDF:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/V3CTQZSM/Patel et al. - 2003 - Evaluating Circuit Reliability under Probabilistic.pdf:application/pdf;Citeseer - Snapshot:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/QVW58S28/summary.html:text/html}
},

@inproceedings{krishnaswamy_accurate_2005,
	title = {Accurate reliability evaluation and enhancement via probabilistic transfer matrices},
	doi = {10.1109/DATE.2005.47},
	abstract = {Soft errors are an increasingly serious problem for logic circuits. To estimate the effects of soft errors on such circuits, we develop a general computational framework based on probabilistic transfer matrices ({PTMs).} In particular, we apply them to evaluate circuit reliability in the presence of soft errors, which involves combining the {PTMs} of gates to form an overall circuit {PTM.} Information, such as output probabilities, the overall probability of error, and signal observability, can then be extracted from the circuit {PTM.} We employ algebraic decision diagrams ({ADDs)} to improve the efficiency of {PTM} operations. A particularly challenging technical problem, solved in our work, is to extend simultaneously tensor products and matrix multiplication in terms of {ADDs} to non-square matrices. Our {PTM-based} method enables accurate evaluation of reliability for moderately large circuits and can be extended by circuit partitioning. To demonstrate the power of the {PTM} approach, we apply it to several problems in fault-tolerant design and reliability improvement.},
	booktitle = {Design, Automation and Test in Europe, 2005. Proceedings},
	author = {Krishnaswamy, S. and Viamontes, {G.F.} and Markov, {I.L.} and Hayes, {J.P.}},
	month = mar,
	year = {2005},
	keywords = {algebraic decision diagrams, Atmospheric modeling, Circuit analysis, circuit partitioning, circuit reliability, circuit reliability evaluation, circuit reliability improvement, Computer architecture, Data mining, decision diagrams, Error probability, error statistics, fault tolerance, fault-tolerant design, logic circuits, logic design, Logic gates, matrix multiplication, Neutrons, Observability, output probabilities, Power system reliability, probabilistic transfer matrices, probability, signal observability, soft errors, Tensile stress, tensor products, tensors},
	pages = {282--287 Vol. 1},
	file = {IEEE Xplore Abstract Record:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/M4EQ92PS/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/9NAPKK8G/Krishnaswamy et al. - 2005 - Accurate reliability evaluation and enhancement vi.pdf:application/pdf}
},

@article{civera_fpga-based_2002,
	title = {An {FPGA-Based} Approach for Speeding-Up Fault Injection Campaigns on Safety-Critical Circuits},
	volume = {18},
	issn = {0923-8174, 1573-0727},
	url = {http://link.springer.com/article/10.1023/A%3A1015079004512},
	doi = {10.1023/A:1015079004512},
	abstract = {In this paper we describe an {FPGA-based} approach to speed-up fault injection campaigns for the evaluation of the fault-tolerance of {VLSI} circuits. Suitable techniques are proposed, allowing emulating the effects of faults and observing faulty behavior. The proposed approach combines the efficiency of hardware-based techniques, and the flexibility of simulation-based techniques. Experimental results are provided showing that significant speed-up figures can be achieved with respect to state-of-the-art simulation-based fault injection techniques.},
	language = {en},
	number = {3},
	urldate = {2014-03-07},
	journal = {Journal of Electronic Testing},
	author = {Civera, P. and Macchiarulo, L. and Rebaudengo, M. and Reorda, M. Sonza and Violante, M.},
	month = jun,
	year = {2002},
	keywords = {Computer-Aided Engineering ({CAD}, {CAE)} and Design, dependability evaluation, Electronic and Computer Engineering, fault injection, fault tolerant circuits, {FPGA-based} fault emulation, Single event upset},
	pages = {261--271},
	file = {Full Text PDF:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/5RQRDZFD/Civera et al. - 2002 - An FPGA-Based Approach for Speeding-Up Fault Injec.pdf:application/pdf;Snapshot:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/2JNXR6DF/10.html:text/html}
},

@article{anthes_inexact_2013,
	title = {Inexact design: beyond fault-tolerance},
	volume = {56},
	issn = {00010782},
	shorttitle = {Inexact design},
	url = {http://cacm.acm.org/magazines/2013/4/162511-inexact-design/fulltext},
	doi = {10.1145/2436256.2436262},
	number = {4},
	urldate = {2014-03-07},
	journal = {Communications of the {ACM}},
	author = {Anthes, Gary},
	month = apr,
	year = {2013},
	pages = {18},
	file = {Inexact Design: Beyond Fault-Tolerance | April 2013 | Communications of the ACM:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/I9HKTTIP/fulltext.html:text/html}
},

@inproceedings{may_resource-efficient_2013,
	title = {A resource-efficient probabilistic fault simulator},
	doi = {10.1109/FPL.2013.6645581},
	abstract = {The reduction of {CMOS} structures into the nanometer regime, as well as the high demand for low-power applications, animating to further reduce the supply voltages towards the threshold, results in an increased susceptibility of integrated circuits to soft errors. Hence, circuit reliability has become a major concern in today's {VLSI} design process. A new approach to further support these trends is to relax the reliability requirements of a circuit, while ensuring that the functionality of the circuit remains unaffected, or effects remain unnoticed by the user. To realize such an approach it is necessary to determine the probability of an error at the output of a circuit, given an error probability distribution at the circuits' elements. Purely software-based simulation approaches are unsuitable due to the large simulation times. Hardware-accelerated approaches exist, but lack the ability to inject errors based on probabilities, are slow or have a large area overhead. In this paper we propose a novel approach for {FPGA-based}, probabilistic, circuit fault simulation. The proposed system is a mainly hardware-based, which makes the simulation fast, but also keeps the hardware overhead on the {FPGA} low by exploiting {FPGA} specific features.},
	booktitle = {2013 23rd International Conference on Field Programmable Logic and Applications ({FPL)}},
	author = {May, D. and Stechele, W.},
	month = sep,
	year = {2013},
	keywords = {circuit elements, Circuit faults, circuit reliability, circuit simulation, Clocks, {CMOS} integrated circuits, {CMOS} structure reduction, Error probability, error probability distribution, error statistics, field programmable gate arrays, {FPGA}, Generators, Integrated circuit modeling, integrated circuit reliability, low-power applications, nanometer regime, probabilistic circuit fault simulation, Probabilistic logic, resource-efficient probabilistic fault simulator, software-based simulation approach, statistical distributions, supply voltages, {VLSI} design process},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/ZCS5HR39/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/AV2RMRTA/May and Stechele - 2013 - A resource-efficient probabilistic fault simulator.pdf:application/pdf}
},

@article{palem_ten_2013,
	title = {Ten Years of Building Broken Chips: The Physics and Engineering of Inexact Computing},
	volume = {12},
	issn = {1539-9087},
	shorttitle = {Ten Years of Building Broken Chips},
	url = {http://doi.acm.org/10.1145/2465787.2465789},
	doi = {10.1145/2465787.2465789},
	abstract = {Well over a decade ago, many believed that an engine of growth driving the semiconductor and computing industries---captured nicely by Gordon Moore’s remarkable prophecy (Moore’s law)---was speeding towards a dangerous cliff-edge. Ranging from expressions of concern to doomsday scenarios, the exact time when serious hurdles would beset us varied quite a bit---some of the more optimistic warnings giving Moore’s law until. Needless to say, a lot of people have spent time and effort with great success to find ways for substantially extending the time when we would encounter the dreaded cliff-edge, if not avoiding it altogether. Faced with this issue, we started approaching this in a decidedly different manner---one which suggested falling off the metaphorical cliff as a design choice, but in a controlled way. This resulted in devices that could switch and produce bits that are correct, namely of having the intended value, only with a probabilistic guarantee. As a result, the results could in fact be incorrect. Such devices and associated circuits and computing structures are now broadly referred to as inexact designs, circuits, and architectures. In this article, we will crystallize the essence of inexactness dating back to 2002 through two key principles that we developed: (i) that of admitting error in a design in return for resource savings, and subsequently (ii) making resource investments in the elements of a hardware platform proportional to the value of information they compute. We will also give a broad overview of a range of inexact designs and hardware concepts that our group and other groups around the world have been developing since, based on these two principles. Despite not being deterministically precise, inexact designs can be significantly more efficient in the energy they consume, their speed of execution, and their area needs, which makes them attractive in application contexts that are resilient to error. Significantly, our development of inexactness will be contrasted against the rich backdrop of traditional approaches aimed at realizing reliable computing from unreliable elements, starting with von Neumann’s influential lectures and further developed by Shannon-Weaver and others.},
	number = {2s},
	urldate = {2014-03-07},
	journal = {{ACM} Trans. Embed. Comput. Syst.},
	author = {Palem, Krishna and Lingamneni, Avinash},
	month = may,
	year = {2013},
	keywords = {Co-design, {EDA}, energy-accuracy trade-off, Inexact Circuit Design, low power/energy, Moore's Law, Probabilistic {CMOS}, {VLSI} design},
	pages = {87:1–87:23},
	file = {ACM Full Text PDF:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/DCM2F7PG/Palem and Lingamneni - 2013 - Ten Years of Building Broken Chips The Physics an.pdf:application/pdf}
},

@article{dodd_basic_2003,
	title = {Basic mechanisms and modeling of single-event upset in digital microelectronics},
	volume = {50},
	issn = {0018-9499},
	doi = {10.1109/TNS.2003.813129},
	abstract = {Physical mechanisms responsible for nondestructive single-event effects in digital microelectronics are reviewed, concentrating on silicon {MOS} devices and integrated circuits. A brief historical overview of single-event effects in space and terrestrial systems is given, and upset mechanisms in dynamic random access memories, static random access memories, and combinational logic are detailed. Techniques for mitigating single-event upset are described, as well as methods for predicting device and circuit single-event response using computer simulations. The impact of technology trends on single-event susceptibility and future areas of concern are explored.},
	number = {3},
	journal = {{IEEE} Transactions on Nuclear Science},
	author = {Dodd, {P.E.} and Massengill, {L.W.}},
	month = jun,
	year = {2003},
	keywords = {charge collection, Circuits, Combinational circuits, combinational logic, digital microelectronics, {DRAM} chips, heavy ion irradiation, integrated circuits, Laboratories, Logic devices, Microelectronics, {MOS} devices, {MOS} digital integrated circuits, nuclear electronics, radiation effects, random access memories, random-access storage, Silicon, silicon {MOS}, Single event upset, single-event upset, Space technology, {SRAM} chips, terrestrial cosmic rays},
	pages = {583--602},
	file = {IEEE Xplore Abstract Record:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/XNWIHA93/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/U7GJGM5U/Dodd and Massengill - 2003 - Basic mechanisms and modeling of single-event upse.pdf:application/pdf}
},

@article{rejimon_probabilistic_2009,
	title = {Probabilistic Error Modeling for Nano-Domain Logic Circuits},
	volume = {17},
	issn = {1063-8210},
	doi = {10.1109/TVLSI.2008.2003167},
	abstract = {In nano-domain logic circuits, errors generated are transient in nature and will arise due to the uncertainty or the unreliability of the computing element itself. This type of errors - which we refer to as dynamic errors - are to be distinguished from traditional faults and radiation related errors. Due to these highly likely dynamic errors, it is more appropriate to model nano-domain computing as probabilistic rather than deterministic. We propose a probabilistic error model based on Bayesian networks to estimate this expected output error probability, given dynamic error probabilities in each device since this estimate is crucial for nano-domain circuit designers to be able to compare and rank designs based on the expected output error. We estimate the overall output error probability by comparing the outputs of a dynamic error-encoded model with an ideal logic model. We prove that this probabilistic framework is a compact and minimal representation of the overall effect of dynamic errors in a circuit. We use both exact and approximate Bayesian inference schemes for propagation of probabilities. The exact inference shows better time performance than the state-of-the art by exploiting conditional independencies exhibited in the underlying probabilistic framework. However, exact inference is worst case {NP-hard} and can handle only small circuits. Hence, we use two approximate inference schemes for medium size benchmarks. We demonstrate the efficiency and accuracy of these approximate inference schemes by comparing estimated results with logic simulation results. We have performed our experiments on {LGSynth'93} and {ISCAS'85} benchmark circuits. We explore our probabilistic model to calculate: 1) error sensitivity of individual gates in a circuit; 2) compute overall exact error probabilities for small circuits; 3) compute approximate error probabilities for medium sized benchmarks using two stochastic sampling schemes; 4) compare and vet design with resp- - ect to dynamic errors; 5) characterize the input space for desired output characteristics by utilizing the unique backtracking capability of Bayesian networks (inverse problem); and 6) to apply selective redundancy to highly sensitive nodes for error tolerant designs.},
	number = {1},
	journal = {{IEEE} Transactions on Very Large Scale Integration ({VLSI)} Systems},
	author = {Rejimon, T. and Lingasubramanian, K. and Bhanja, S.},
	month = jan,
	year = {2009},
	keywords = {Bayesian inference schemes, Bayesian networks, belief networks, dynamic error-encoded model, dynamic errors, error sensitivity, error statistics, error tolerant designs, inference mechanisms, logic {CAD}, logic circuits, Logic gates, nano-domain computing, nano-domain logic circuits, Network synthesis, output error probability, probabilistic error model, probabilistic error modeling, radiation related errors, stochastic sampling schemes},
	pages = {55--65},
	file = {IEEE Xplore Abstract Record:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/AM884WMB/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/SIM5CWSM/Rejimon et al. - 2009 - Probabilistic Error Modeling for Nano-Domain Logic.pdf:application/pdf}
},

@inproceedings{leveugle_statistical_2009,
	title = {Statistical fault injection: Quantified error and confidence},
	shorttitle = {Statistical fault injection},
	doi = {10.1109/DATE.2009.5090716},
	abstract = {Fault injection has become a very classical method to determine the dependability of an integrated system with respect to soft errors. Due to the huge number of possible error configurations in complex circuits, a random selection of a subset of potential errors is usual in practical experiments. The main limitation of such a selection is the confidence in the outcomes that is never quantified in the articles. This paper proposes an approach to quantify both the error on the presented results and the confidence on the presented interval. The computation of the required number of faults to inject in order to achieve a given confidence and error interval is also discussed. Experimental results are shown and fully support the presented approach.},
	booktitle = {Design, Automation Test in Europe Conference Exhibition, 2009. {DATE} '09.},
	author = {Leveugle, R. and Calvez, A. and Maistri, P. and Vanhauwaert, P.},
	month = apr,
	year = {2009},
	keywords = {Alpha particles, Circuit faults, dependability analysis, electromagnetic interference, Emulation, fault diagnosis, Indium phosphide, integrated circuit, Integrated circuit manufacture, Integrated circuit technology, integrated circuits, Laboratories, Neutrons, Sea level, statistical analysis, statistical fault injection},
	pages = {502--506},
	file = {IEEE Xplore Abstract Record:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/HWNZ3T6V/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/CB5AAF3H/Leveugle et al. - 2009 - Statistical fault injection Quantified error and .pdf:application/pdf}
},

@article{lingamneni_synthesizing_2013,
	title = {Synthesizing Parsimonious Inexact Circuits Through Probabilistic Design Techniques},
	volume = {12},
	issn = {1539-9087},
	url = {http://doi.acm.org/10.1145/2465787.2465795},
	doi = {10.1145/2465787.2465795},
	abstract = {The domain of inexact circuit design, in which accuracy of the circuit can be exchanged for substantial cost (energy, delay, and/or area) savings, has been gathering increasing prominence of late owing to a growing desire for reducing energy consumption of the systems, particularly in the domain of embedded and (portable) multimedia applications. Most of the previous approaches to realizing inexact circuits relied on scaling of circuit parameters (such as supply voltage) taking advantage of an application’s error tolerance to achieve the cost and accuracy trade-offs, thus suffering from acute drawbacks of considerable implementation overheads that significantly reduced the gains. In this article, two novel design approaches called Probabilistic Pruning and Probabilistic Logic Minimization are proposed to realize inexact circuits with zero hardware {overhead.Extensive} simulations on various architectures of critical datapath elements demonstrate that each of the techniques can independently achieve normalized gains as large as 2x--9.5x in energy-delay-area product for relative error magnitude as low as 10 − 4\%--8\% compared to corresponding conventional correct circuits.},
	number = {2s},
	urldate = {2014-03-07},
	journal = {{ACM} Trans. Embed. Comput. Syst.},
	author = {Lingamneni, Avinash and Enz, Christian and Palem, Krishna and Piguet, Christian},
	month = may,
	year = {2013},
	keywords = {energy-accuracy trade-off, error-tolerant systems, Inexact Circuit Design, low power/energy, probabilistic logic minimization, probabilistic pruning, {VLSI} design},
	pages = {93:1–93:26},
	file = {ACM Full Text PDF:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/VIKJEKHE/Lingamneni et al. - 2013 - Synthesizing Parsimonious Inexact Circuits Through.pdf:application/pdf}
},

@article{baze_seu_1995,
	title = {An {SEU} analysis approach for error propagation in digital {VLSI} {CMOS} {ASICs}},
	volume = {42},
	issn = {0018-9499},
	doi = {10.1109/23.489228},
	abstract = {A probabilistic description of error propagation in complex circuits is formulated and solved as a set of linear equations. Comparisons are made with experimental data},
	number = {6},
	journal = {{IEEE} Transactions on Nuclear Science},
	author = {Baze, M. P. and Buchner, S. and Bartholet, {W.G.} and Dao, {T.A.}},
	month = dec,
	year = {1995},
	keywords = {Application specific integrated circuits, circuit simulation, {CMOS} digital integrated circuits, complex circuits, Computer errors, digital {VLSI} {CMOS} {ASICs}, Discrete event simulation, Equations, Error analysis, error propagation, errors, Fabrication, linear equations, logic circuits, probabilistic theory, Registers, {SEU} analysis, Very large scale integration, {VLSI}},
	pages = {1863--1869},
	file = {IEEE Xplore Abstract Record:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/E98A7KG7/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/ZKUAJRE4/Baze et al. - 1995 - An SEU analysis approach for error propagation in .pdf:application/pdf}
},

@inproceedings{gimmler-dumont_asic_2013,
	title = {{ASIC} implementation of a modified {QR} decomposition for tree search based {MIMO} detection},
	doi = {10.1109/LASCAS.2013.6519049},
	abstract = {Multiple-antenna systems offer very attractive gains in data rates and transmission reliability. Therefore, they are employed in many modern communication standards. However, the detection and separation of these multiple data streams can be very complex. For tree search based detection methods, a channel preprocessing is mandatory which consists mainly of a {QR} matrix decomposition. We propose a modification of the standard {QR} matrix decomposition which simplifies the tree search while not increasing the complexity of the {QR} decomposition. We present hardware architectures of the original and the modified {QR} decomposition. The resulting {ASIC} implementation in 65nm technology runs at a maximum clock frequency of 370 {MHz} and consumes an area of 0.14mm2. The power consumption at the specified clock frequency of 300 {MHz} is only {6.8mW.}},
	booktitle = {2013 {IEEE} Fourth Latin American Symposium on Circuits and Systems ({LASCAS)}},
	author = {Gimmler-Dumont, C. and Schlafer, P. and Wehn, N.},
	month = feb,
	year = {2013},
	keywords = {antenna arrays, Application specific integrated circuits, {ASIC} implementation, channel preprocessing, Communication standards, data rates, data stream detection, data stream separation, frequency 300 {MHz}, frequency 370 {MHz}, matrix decomposition, {MIMO} communication, modified {QR} decomposition, multiple-antenna systems, power 6.8 {mW}, {QR} matrix decomposition, signal detection, size 65 nm, source separation, Telecommunication network reliability, transmission reliability, tree search-based {MIMO} detection, tree searching},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/CCQ2MCPC/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/D7FDJEE8/Gimmler-Dumont et al. - 2013 - ASIC implementation of a modified QR decomposition.pdf:application/pdf}
},

@book{loeve_probability_1978,
	title = {Probability Theory I},
	isbn = {9780387902104},
	language = {en},
	publisher = {Springer},
	author = {Loeve, M.},
	year = {1978},
	keywords = {Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes}
},

@inproceedings{herkersdorf_cross-layer_2013,
	title = {Cross-layer dependability modeling and abstraction in systems on chip},
	url = {http://softerrors.info/selse/images/selse_2013/papers/18selse2013_submission_9.pdf},
	urldate = {2014-03-07},
	booktitle = {Workshop on Silicon Errors in Logic-System Effects ({SELSE)}},
	author = {Herkersdorf, Andreas and Engel, Michael and Gla{\textbackslash}s s, Michael and Henkel, Jörg and Kleeberger, Veit B. and Kochte, Michael A. and Kühn, Johannes M. and Nassif, Sani R. and Rauchfuss, Holm and Rosenstiel, Wolfgang},
	year = {2013},
	file = {[PDF] von softerrors.info:/home/david/.mozilla/firefox/3jm0sgvo.default/zotero/storage/5X54H2WC/Herkersdorf et al. - 2013 - Cross-layer dependability modeling and abstraction.pdf:application/pdf}
}
